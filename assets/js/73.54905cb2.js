(window.webpackJsonp=window.webpackJsonp||[]).push([[73],{385:function(s,t,a){"use strict";a.r(t);var n=a(7),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"枚举类"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#枚举类"}},[s._v("#")]),s._v(" 枚举类")]),s._v(" "),t("h2",{attrs:{id:"简单使用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#简单使用"}},[s._v("#")]),s._v(" 简单使用")]),s._v(" "),t("div",{staticClass:"language-python extra-class"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" enum "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Enum\n\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Weekday")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Enum"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    MONDAY "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n    TUESDAY "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\n    WEDNESDAY "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\n    THURSDAY "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("\n    FRIDAY "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v("\n    SATURDAY "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v("\n    SUNDAY "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v("\n\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# The special attribute __members__ is a read-only ordered mapping of names to members.")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# It includes all names defined in the enumeration, including the aliases:")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" member "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" Weekday"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("__members__"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("items"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" member"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" member"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("value"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),t("ol",[t("li",[s._v("枚举类的"),t("code",[s._v("__members__")]),s._v("是一个只读的字典")])]),s._v(" "),t("h2",{attrs:{id:"unique"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#unique"}},[s._v("#")]),s._v(" "),t("code",[s._v("@unique")])]),s._v(" "),t("div",{staticClass:"language-python extra-class"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" enum "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Enum"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" unique\n"),t("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[s._v("@unique")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Mistake")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Enum"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    ONE "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n    TWO "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 不允许同样的key")]),s._v("\n    THREE "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\n    FOUR "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\n\n")])])])])}),[],!1,null,null,null);t.default=e.exports}}]);